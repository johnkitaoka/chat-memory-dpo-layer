[2024-06-26 14:20:00] USER: I need to set up a CI/CD pipeline for a Python web app. What's the best approach using GitHub Actions?
[2024-06-26 14:20:30] ASSISTANT: Here's a comprehensive GitHub Actions CI/CD pipeline for Python web applications:

## Basic Workflow Structure

```yaml
# .github/workflows/ci-cd.yml
name: CI/CD Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]

jobs:
  test:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: [3.9, 3.10, 3.11]
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install pytest pytest-cov flake8
    
    - name: Lint with flake8
      run: |
        flake8 . --count --select=E9,F63,F7,F82 --show-source --statistics
        flake8 . --count --exit-zero --max-complexity=10 --max-line-length=127 --statistics
    
    - name: Test with pytest
      run: |
        pytest --cov=./ --cov-report=xml
    
    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.xml
```

This covers testing across multiple Python versions with linting and coverage reporting. Would you like me to add the deployment stages?
[2024-06-26 14:22:00] USER: Yes, show me how to add deployment to both staging and production environments.
[2024-06-26 14:22:45] ASSISTANT: Here's the complete CI/CD pipeline with staging and production deployments:

```yaml
name: CI/CD Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]

env:
  REGISTRY: ghcr.io
  IMAGE_NAME: ${{ github.repository }}

jobs:
  test:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: [3.9, 3.10, 3.11]
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install pytest pytest-cov flake8 black
    
    - name: Format check with black
      run: black --check .
    
    - name: Lint with flake8
      run: |
        flake8 . --count --select=E9,F63,F7,F82 --show-source --statistics
        flake8 . --count --exit-zero --max-complexity=10 --max-line-length=127 --statistics
    
    - name: Test with pytest
      run: pytest --cov=./ --cov-report=xml
    
    - name: Upload coverage
      uses: codecov/codecov-action@v3

  build:
    needs: test
    runs-on: ubuntu-latest
    if: github.event_name == 'push'
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Log in to Container Registry
      uses: docker/login-action@v2
      with:
        registry: ${{ env.REGISTRY }}
        username: ${{ github.actor }}
        password: ${{ secrets.GITHUB_TOKEN }}
    
    - name: Extract metadata
      id: meta
      uses: docker/metadata-action@v4
      with:
        images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}
        tags: |
          type=ref,event=branch
          type=sha,prefix={{branch}}-
    
    - name: Build and push Docker image
      uses: docker/build-push-action@v4
      with:
        context: .
        push: true
        tags: ${{ steps.meta.outputs.tags }}
        labels: ${{ steps.meta.outputs.labels }}

  deploy-staging:
    needs: build
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/develop'
    environment: staging
    
    steps:
    - name: Deploy to staging
      run: |
        echo "Deploying to staging environment..."
        # Add your staging deployment commands here
        # Example: kubectl, docker-compose, or cloud provider CLI
    
    - name: Run smoke tests
      run: |
        echo "Running smoke tests against staging..."
        # Add staging verification tests

  deploy-production:
    needs: build
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    environment: production
    
    steps:
    - name: Deploy to production
      run: |
        echo "Deploying to production environment..."
        # Add your production deployment commands here
    
    - name: Run health checks
      run: |
        echo "Running production health checks..."
        # Add production verification
```

## Docker Configuration

Create a `Dockerfile`:

```dockerfile
FROM python:3.11-slim

WORKDIR /app

COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

COPY . .

EXPOSE 8000

CMD ["gunicorn", "--bind", "0.0.0.0:8000", "app:app"]
```

## Environment-Specific Configs

Set up GitHub environments with protection rules and secrets. Would you like me to show specific deployment examples for AWS, GCP, or Kubernetes?
[2024-06-26 14:25:00] USER: Can you show me how to deploy to AWS ECS with this pipeline?
[2024-06-26 14:25:30] ASSISTANT: Here's how to deploy to AWS ECS using the GitHub Actions pipeline:

## ECS Deployment Configuration

```yaml
  deploy-staging:
    needs: build
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/develop'
    environment: staging
    
    steps:
    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v2
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: us-east-1
    
    - name: Download task definition
      run: |
        aws ecs describe-task-definition \
          --task-definition myapp-staging \
          --query taskDefinition > task-definition.json
    
    - name: Update ECS task definition
      id: task-def
      uses: aws-actions/amazon-ecs-render-task-definition@v1
      with:
        task-definition: task-definition.json
        container-name: myapp
        image: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:develop-${{ github.sha }}
    
    - name: Deploy to ECS
      uses: aws-actions/amazon-ecs-deploy-task-definition@v1
      with:
        task-definition: ${{ steps.task-def.outputs.task-definition }}
        service: myapp-staging-service
        cluster: myapp-staging-cluster
        wait-for-service-stability: true
    
    - name: Verify deployment
      run: |
        # Wait for deployment to stabilize
        sleep 30
        
        # Get service endpoint
        ENDPOINT=$(aws ecs describe-services \
          --cluster myapp-staging-cluster \
          --services myapp-staging-service \
          --query 'services[0].loadBalancers[0].targetGroupArn' \
          --output text)
        
        # Health check
        curl -f https://staging.myapp.com/health || exit 1

  deploy-production:
    needs: build
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    environment: production
    
    steps:
    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v2
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: us-east-1
    
    - name: Download task definition
      run: |
        aws ecs describe-task-definition \
          --task-definition myapp-production \
          --query taskDefinition > task-definition.json
    
    - name: Update ECS task definition
      id: task-def
      uses: aws-actions/amazon-ecs-render-task-definition@v1
      with:
        task-definition: task-definition.json
        container-name: myapp
        image: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:main-${{ github.sha }}
    
    - name: Deploy to ECS
      uses: aws-actions/amazon-ecs-deploy-task-definition@v1
      with:
        task-definition: ${{ steps.task-def.outputs.task-definition }}
        service: myapp-production-service
        cluster: myapp-production-cluster
        wait-for-service-stability: true
    
    - name: Run production health checks
      run: |
        # Comprehensive health checks
        curl -f https://api.myapp.com/health
        curl -f https://api.myapp.com/metrics
        
        # Database connectivity check
        python -c "
        import requests
        response = requests.get('https://api.myapp.com/db-health')
        assert response.status_code == 200
        assert response.json()['status'] == 'healthy'
        "
```

## ECS Task Definition Template

Create `task-definition-template.json`:

```json
{
  "family": "myapp-production",
  "networkMode": "awsvpc",
  "requiresCompatibilities": ["FARGATE"],
  "cpu": "512",
  "memory": "1024",
  "executionRoleArn": "arn:aws:iam::ACCOUNT:role/ecsTaskExecutionRole",
  "taskRoleArn": "arn:aws:iam::ACCOUNT:role/ecsTaskRole",
  "containerDefinitions": [
    {
      "name": "myapp",
      "image": "IMAGE_URI_PLACEHOLDER",
      "portMappings": [
        {
          "containerPort": 8000,
          "protocol": "tcp"
        }
      ],
      "environment": [
        {
          "name": "ENV",
          "value": "production"
        }
      ],
      "secrets": [
        {
          "name": "DATABASE_URL",
          "valueFrom": "arn:aws:secretsmanager:us-east-1:ACCOUNT:secret:prod/database-url"
        }
      ],
      "logConfiguration": {
        "logDriver": "awslogs",
        "options": {
          "awslogs-group": "/ecs/myapp-production",
          "awslogs-region": "us-east-1",
          "awslogs-stream-prefix": "ecs"
        }
      },
      "healthCheck": {
        "command": ["CMD-SHELL", "curl -f http://localhost:8000/health || exit 1"],
        "interval": 30,
        "timeout": 5,
        "retries": 3,
        "startPeriod": 60
      }
    }
  ]
}
```

## Required GitHub Secrets

Set these in your repository settings:
- `AWS_ACCESS_KEY_ID`
- `AWS_SECRET_ACCESS_KEY`

## AWS Infrastructure Setup

You'll need to create:
1. ECS Clusters (staging and production)
2. ECS Services
3. Application Load Balancer
4. Target Groups
5. IAM roles for ECS tasks

Would you like me to show you the Terraform configuration for setting up the AWS infrastructure?
[2024-06-26 14:28:00] USER: That's perfect! Can you also show me how to add database migrations to this pipeline?
[2024-06-26 14:28:30] ASSISTANT: Here's how to add database migrations to your ECS deployment pipeline:

## Migration Job in GitHub Actions

```yaml
  migrate-staging:
    needs: build
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/develop'
    environment: staging
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v2
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: us-east-1
    
    - name: Run database migrations
      run: |
        # Create one-time migration task
        aws ecs run-task \
          --cluster myapp-staging-cluster \
          --task-definition myapp-migration-staging \
          --launch-type FARGATE \
          --network-configuration "awsvpcConfiguration={subnets=[subnet-12345],securityGroups=[sg-12345],assignPublicIp=ENABLED}" \
          --overrides '{
            "containerOverrides": [
              {
                "name": "myapp-migration",
                "command": ["python", "manage.py", "migrate"]
              }
            ]
          }' > task-arn.json
        
        # Wait for migration to complete
        TASK_ARN=$(cat task-arn.json | jq -r '.tasks[0].taskArn')
        aws ecs wait tasks-stopped --cluster myapp-staging-cluster --tasks $TASK_ARN
        
        # Check if migration succeeded
        EXIT_CODE=$(aws ecs describe-tasks \
          --cluster myapp-staging-cluster \
          --tasks $TASK_ARN \
          --query 'tasks[0].containers[0].exitCode' \
          --output text)
        
        if [ "$EXIT_CODE" != "0" ]; then
          echo "Migration failed with exit code: $EXIT_CODE"
          exit 1
        fi

  deploy-staging:
    needs: migrate-staging  # Changed dependency
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/develop'
    environment: staging
    # ... rest of staging deployment

  migrate-production:
    needs: build
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    environment: production
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v2
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: us-east-1
    
    - name: Create database backup
      run: |
        # Create RDS snapshot before migration
        SNAPSHOT_ID="pre-migration-$(date +%Y%m%d-%H%M%S)"
        aws rds create-db-snapshot \
          --db-instance-identifier myapp-prod-db \
          --db-snapshot-identifier $SNAPSHOT_ID
        
        # Wait for snapshot to complete
        aws rds wait db-snapshot-completed \
          --db-snapshot-identifier $SNAPSHOT_ID
        
        echo "Backup created: $SNAPSHOT_ID"
    
    - name: Run database migrations
      run: |
        # Run migration with timeout and monitoring
        aws ecs run-task \
          --cluster myapp-production-cluster \
          --task-definition myapp-migration-production \
          --launch-type FARGATE \
          --network-configuration "awsvpcConfiguration={subnets=[subnet-67890],securityGroups=[sg-67890],assignPublicIp=ENABLED}" \
          --overrides '{
            "containerOverrides": [
              {
                "name": "myapp-migration",
                "command": ["python", "manage.py", "migrate", "--verbosity=2"]
              }
            ]
          }' > task-arn.json
        
        TASK_ARN=$(cat task-arn.json | jq -r '.tasks[0].taskArn')
        
        # Monitor migration progress
        echo "Migration task started: $TASK_ARN"
        aws ecs wait tasks-stopped --cluster myapp-production-cluster --tasks $TASK_ARN
        
        # Verify migration success
        EXIT_CODE=$(aws ecs describe-tasks \
          --cluster myapp-production-cluster \
          --tasks $TASK_ARN \
          --query 'tasks[0].containers[0].exitCode' \
          --output text)
        
        if [ "$EXIT_CODE" != "0" ]; then
          echo "Migration failed! Check CloudWatch logs."
          exit 1
        fi
        
        echo "Migration completed successfully"

  deploy-production:
    needs: migrate-production  # Changed dependency
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    environment: production
    # ... rest of production deployment
```

## Migration Task Definition

Create `migration-task-definition.json`:

```json
{
  "family": "myapp-migration-production",
  "networkMode": "awsvpc",
  "requiresCompatibilities": ["FARGATE"],
  "cpu": "256",
  "memory": "512",
  "executionRoleArn": "arn:aws:iam::ACCOUNT:role/ecsTaskExecutionRole",
  "taskRoleArn": "arn:aws:iam::ACCOUNT:role/ecsTaskRole",
  "containerDefinitions": [
    {
      "name": "myapp-migration",
      "image": "IMAGE_URI_PLACEHOLDER",
      "essential": true,
      "environment": [
        {
          "name": "ENV",
          "value": "production"
        }
      ],
      "secrets": [
        {
          "name": "DATABASE_URL",
          "valueFrom": "arn:aws:secretsmanager:us-east-1:ACCOUNT:secret:prod/database-url"
        }
      ],
      "logConfiguration": {
        "logDriver": "awslogs",
        "options": {
          "awslogs-group": "/ecs/myapp-migration-production",
          "awslogs-region": "us-east-1",
          "awslogs-stream-prefix": "migration"
        }
      }
    }
  ]
}
```

## Django Migration Script

Add to your Docker image (`scripts/migrate.py`):

```python
#!/usr/bin/env python
import os
import sys
import django
from django.core.management import execute_from_command_line
from django.db import connection
from django.core.management.base import BaseCommand

def check_database_connection():
    """Verify database is accessible before migration"""
    try:
        with connection.cursor() as cursor:
            cursor.execute("SELECT 1")
        print("✓ Database connection successful")
        return True
    except Exception as e:
        print(f"✗ Database connection failed: {e}")
        return False

def run_migrations():
    """Run Django migrations with proper error handling"""
    if not check_database_connection():
        sys.exit(1)
    
    try:
        # Check for pending migrations
        execute_from_command_line(['manage.py', 'showmigrations', '--plan'])
        
        # Run migrations
        execute_from_command_line(['manage.py', 'migrate', '--verbosity=2'])
        
        print("✓ Migrations completed successfully")
        
    except Exception as e:
        print(f"✗ Migration failed: {e}")
        sys.exit(1)

if __name__ == '__main__':
    os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'myapp.settings')
    django.setup()
    run_migrations()
```

## Rollback Strategy

Add rollback capability:

```yaml
  rollback-production:
    runs-on: ubuntu-latest
    if: failure() && github.ref == 'refs/heads/main'
    environment: production
    
    steps:
    - name: Rollback deployment
      run: |
        # Get previous task definition
        PREVIOUS_REVISION=$(aws ecs describe-services \
          --cluster myapp-production-cluster \
          --services myapp-production-service \
          --query 'services[0].taskDefinition' \
          --output text | sed 's/:.*/:$(($(echo $TASK_DEF | cut -d: -f2) - 1))')
        
        # Rollback service
        aws ecs update-service \
          --cluster myapp-production-cluster \
          --service myapp-production-service \
          --task-definition $PREVIOUS_REVISION
        
        echo "Service rolled back to: $PREVIOUS_REVISION"
```

This setup ensures migrations run before deployment and includes proper error handling, backups, and rollback capabilities. The migrations run as separate ECS tasks to avoid affecting your main application containers.
[2024-06-26 14:32:00] USER: Excellent! This gives me a complete production-ready CI/CD pipeline. Thanks for the detailed examples.
[2024-06-26 14:32:15] ASSISTANT: You're welcome! You now have a comprehensive, production-ready CI/CD pipeline with:

## Complete Pipeline Features:
- ✅ Multi-environment testing (Python 3.9-3.11)
- ✅ Code quality checks (Black, Flake8)
- ✅ Docker containerization
- ✅ Staging and production deployments
- ✅ Database migrations with backups
- ✅ Health checks and verification
- ✅ Rollback capabilities
- ✅ Proper AWS ECS integration

## Key Benefits:
- **Safety**: Automated backups before production migrations
- **Reliability**: Health checks and rollback mechanisms
- **Visibility**: Comprehensive logging and monitoring
- **Scalability**: ECS Fargate for container orchestration

## Next Steps:
1. Set up your AWS infrastructure (ECS clusters, RDS, IAM roles)
2. Configure GitHub environments and secrets
3. Test the pipeline with a simple deployment
4. Add monitoring and alerting (CloudWatch, Slack notifications)

This pipeline follows industry best practices and should serve you well for production workloads. Feel free to reach out if you need help with the AWS setup or want to add additional features like blue-green deployments!
[2024-06-26 14:32:30] USER: Perfect, I'll start implementing this right away!
